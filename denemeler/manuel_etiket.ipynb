{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:09:40.635496Z",
     "start_time": "2025-07-18T12:09:40.585097Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Değerlendirme ---\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        13\n",
      "           1       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.81        21\n",
      "   macro avg       0.80      0.80      0.80        21\n",
      "weighted avg       0.81      0.81      0.81        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ŞEVVAL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Feature kelime listeleri\n",
    "pozitif_kelimeler = [\n",
    "    \"harika\", \"mükemmel\", \"tavsiye\", \"rahat\", \"hızlı\", \"güzel\", \"ideal\", \"kaliteli\",\n",
    "    \"süper\", \"beğendim\", \"memnun\", \"iyi\", \"şahane\", \"harikulade\",  \"keyifli\", \"ucuz\"\n",
    "]\n",
    "\n",
    "negatif_kelimeler = [\n",
    "    \"kırık\", \"bozuk\", \"sert\", \"rahatsız\", \"berbat\", \"iade\", \"gıcırtı\", \"sıkıntı\",\n",
    "    \"kötü\", \"patladı\", \"rezalet\", \"arıza\", \"dayanıksız\", \"paslı\", \n",
    "]\n",
    "\n",
    "\n",
    "# 1. JSON dosyasını oku\n",
    "def load_reviews_from_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return [review.get(\"comment\", \"\") for review in data[\"reviews\"]]\n",
    "\n",
    "# 2. Yukardaki kelimeleri kullanarak yorumların etiketlerini otomatik olarak belirleme\n",
    "def auto_label(yorumlar):\n",
    "    etiketler = []\n",
    "    for yorum in yorumlar:\n",
    "        y = yorum.lower()\n",
    "        pos = any(poz in y for poz in pozitif_kelimeler)\n",
    "        neg = any(neg in y for neg in negatif_kelimeler)\n",
    "        if pos and not neg:\n",
    "            etiketler.append(1)     # pozitif\n",
    "        elif neg and not pos:\n",
    "            etiketler.append(-1)    # negatif\n",
    "        else:\n",
    "            etiketler.append(0)     # nötr\n",
    "    return etiketler\n",
    "\n",
    "# 3. Model eğitimi\n",
    "def egit_model(yorumlar, etiketler):\n",
    "    vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(yorumlar)\n",
    "    y = etiketler\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Eğitim sırasında class_weight kullan:\n",
    "    model = LogisticRegression(multi_class='multinomial', max_iter=1000, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"\\n--- Değerlendirme ---\\n\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    return model, vectorizer\n",
    "\n",
    "# 4. Uygulama\n",
    "yorumlar = load_reviews_from_json(\"response.json\")\n",
    "etiketler = auto_label(yorumlar)\n",
    "model, vectorizer = egit_model(yorumlar, etiketler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4491ca7d584b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-18T12:05:29.400485Z",
     "start_time": "2025-07-18T12:05:29.390695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bisiklet bozuk geldi', np.int64(1)), ('Gerçekten çok kaliteli', np.int64(1)), ('Koltuk biraz rahatsız ama idare eder', np.int64(0)), ('Bisiklet yakıyor', np.int64(1)), ('Bisiklet çok iyi', np.int64(1)), ('Bisiklet çok iyi', np.int64(1)), ('Berbat', np.int64(0)), ('Süper', np.int64(1)), ('Selesi çok sert', np.int64(0))]\n"
     ]
    }
   ],
   "source": [
    "def tahmin_et(model, vectorizer, yeni_yorumlar):\n",
    "    X_new = vectorizer.transform(yeni_yorumlar)\n",
    "    tahminler = model.predict(X_new)\n",
    "    return list(zip(yeni_yorumlar, tahminler))\n",
    "\n",
    "# Örnek:\n",
    "yeni = [\"Bisiklet bozuk geldi\", \"Gerçekten çok kaliteli\", \"Koltuk biraz rahatsız ama idare eder\", \"Bisiklet yakıyor\", \n",
    "\"Bisiklet çok iyi\", \"Bisiklet çok iyi\", \"Berbat\", \"Süper\", \"Selesi çok sert\"]\n",
    "print(tahmin_et(model, vectorizer, yeni))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb62eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 62, 1: 37, -1: 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(etiketler))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
